{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Preprocessing and Exploratory Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data\n",
    "\n",
    "The raw data file 'data/data_2017.csv' contains two comma-separated columns. The first is the (unicode) text of a comment, and the second is the subreddit in which it was posted. \n",
    "\n",
    "These comments were downloaded from a Google BigQuery public dataset. They are the top 2000 comments in each subreddit (ranked by score) from the top 1000 subreddits (ranked by number of comments) for a total of about 2,000,000 comments. To stay within memory constraints on BigQuery (and to introduce some stochasticity), these are taken from a 10% random sample of all the comments posted to Reddit in October 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data...\n",
      "done in 6.291s\n",
      "                                                      body      subreddit\n",
      "184951        Yes, but it's not supposed to last forever.           DiWHY\n",
      "126137   Everyone in my family plays: 1 rushed TH11 (7/...   ClashOfClans\n",
      "1535222  Absolutely correct. People don't think somethi...  AdviceAnimals\n",
      "507184                                           [deleted]    slavelabour\n",
      "1180399  Hmm, then idk; I only started binding (correct...            ftm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "print(\"Importing data...\")\n",
    "t0 = time()\n",
    "data = pd.read_csv('data/data_2017.csv', dtype='str')\n",
    "print(\"done in %0.3fs\" % (time()-t0))\n",
    "\n",
    "print(data.sample(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View class sizes before preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1892353 comments across 1000 subreddits.\n",
      "\n",
      "    num_comments         subreddit\n",
      "0           1262         apolloapp\n",
      "1           1283       exchristian\n",
      "2           1305      circlebroke2\n",
      "3           1312              suns\n",
      "4           1313  shittyaskscience\n",
      "995         2000           writing\n",
      "996         2000           xboxone\n",
      "997         2000         xxfitness\n",
      "998         2000      youtubehaiku\n",
      "999         2000            yugioh\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFlCAYAAAA6QpuEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhAY7vwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2cb103cee10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "subs = data.loc[:,'subreddit'].drop_duplicates()\n",
    "\n",
    "# Slice dataframe along those subreddit keywords, save the length of the slice in a dict\n",
    "subsize = {}\n",
    "for subreddit in subs:\n",
    "    subsize[subreddit] = len(data[data['subreddit']==subreddit].index)\n",
    "    \n",
    "# Sort the dict and store in a dataframe\n",
    "sizes = pd.DataFrame(np.array([list(map(int,(sorted(list(subsize.values()))))),\n",
    "                       sorted(subsize, key=lambda x: (subsize[x], x))]).T,\n",
    "                     columns=('num_comments','subreddit'))\n",
    "\n",
    "print(\"There are {} comments across {} subreddits.\".format(sum(sizes['num_comments'].astype(int)),len(subs)))\n",
    "print()\n",
    "\n",
    "# Print subreddits with fewest and greatest numbers of comments\n",
    "print(sizes.iloc[pd.np.r_[:5, -5:0]])\n",
    "\n",
    "sns.distplot(sizes['num_comments'].astype(int), kde=False, hist=True, bins=100);\n",
    "plt.title(\"Distribution of the number of comments over subreddit label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove top non-English-language subreddits\n",
    "These were discovered by hand after filtering non-English characters. In production, this process should be automated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data[data['subreddit'] != 'newsokur']\n",
    "data = data[data['subreddit'] != 'Womad']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove deleted comments\n",
    "When a comment with children is removed from reddit, it is replaced with one of the dummy comments \"[deleted]\" or \"[removed]\". While the proportion of such removals to the comment section as a whole may be an intriguing feature, we do not explore it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.85% of the comments were deleted or removed before they could be archived.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sfzba\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These have been removed from the data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deleteds = data.body=='[deleted]'\n",
    "removeds = data.body=='[removed]'\n",
    "print('{:.2f}% of the comments were deleted or removed before they could be archived.'.format(\n",
    "    100*(sum(deleteds)+sum(removeds))/len(data.index)))\n",
    "data = data[~deleteds]\n",
    "data = data[~removeds]\n",
    "print('These have been removed from the data.')\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove markdown and non-english characters\n",
    "Reddit has a basic markdown syntax (https://www.reddit.com/r/reddit.com/comments/6ewgt/reddit_markdown_primer_or_how_do_you_do_all_that/c03nik6/). These symbols and more are removed from the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# formatting markdown\n",
    "md = re.compile(r\"\"\"\n",
    "                [~#_`\\*\\+\\^=>]+ # common markdown formatting symbols\n",
    "                |&gt;+          # indent \">\" is stored improperly sometimes\n",
    "                \"\"\", re.VERBOSE)\n",
    "# link markdown\n",
    "lk = re.compile(r\"\"\"(\\[(.*?)\\])?\\(.*?\\)| # usual markdown links\n",
    "                \\/[ur]\\/(\\S+)            # reddit-internal links\n",
    "                \"\"\", re.VERBOSE)\n",
    "# currency marks\n",
    "dl = re.compile(r'\\$(\\d*)') # dollar sign\n",
    "br = re.compile(r'£(\\d*)')  # pound sign\n",
    "eu = re.compile(r'€(\\d*)')  # euro sign\n",
    "# percent sign\n",
    "pc = re.compile(r'(\\d*)%')\n",
    "# ampersand\n",
    "am = re.compile(r'&amp;|&')\n",
    "# enforce ASCII alphanumerics (+é) and common punctuation\n",
    "en = re.compile(r'[^\\w\\s,.:;\\-\\'\\\"\\[\\]\\(\\)!\\?\\/\\\\é]+', re.ASCII)\n",
    "\n",
    "def preprocess(text):\n",
    "    text = md.sub(r\"\", text)\n",
    "    text = lk.sub(r\" \\2\\3 \", text)\n",
    "    text = dl.sub(r'\\1 dollars', text)\n",
    "    text = br.sub(r'\\1 pounds', text)\n",
    "    text = eu.sub(r'\\1 euros', text)\n",
    "    text = pc.sub(r'\\1 percent', text)\n",
    "    text = am.sub(r' and ', text)\n",
    "    text = en.sub(r' ', text)\n",
    "    return text    \n",
    "\n",
    "%time data['body'] = data['body'].astype('unicode').apply(preprocess)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove blank comments\n",
    "After the above processing steps, some comments may be blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17% of the comments were blank after preprocessing.\n",
      "These have been removed from the data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blanks = data['body'].str.contains(r'^[\\s]*$')\n",
    "print('{:.2f}% of the comments were blank after preprocessing.'.format(100*sum(blanks)/len(data.index)))\n",
    "data = data[~blanks]\n",
    "print('These have been removed from the data.')\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataframe to use in later evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_pickle('data/prepped.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-preprocessing Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review class sizes\n",
    "It would be better to write this as a function, rather than write out the code twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "subsize = {}\n",
    "subs = data.loc[:,'subreddit'].drop_duplicates()\n",
    "for subreddit in subs:\n",
    "    subsize[subreddit] = len(data[data['subreddit']==subreddit].index)\n",
    "sizes = pd.DataFrame(np.array([sorted(list(subsize.values())),\n",
    "                       sorted(subsize, key=lambda x: (subsize[x], x))]).T,\n",
    "                     columns=('num_comments','subreddit'))\n",
    "\n",
    "print(\"There are {} comments across {} subreddits.\".format(sum(sizes['num_comments'].astype(int)),len(subs)))\n",
    "print()\n",
    "\n",
    "print(sizes.iloc[pd.np.r_[:5, -5:0]])\n",
    "\n",
    "sns.distplot(sizes['num_comments'].astype(int), kde=False, hist=True, bins=100);\n",
    "plt.title(\"Distribution of the number of comments over subreddit label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordclouds from random subreddits\n",
    "Again, these wordcloud generations should be function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "wc = WordCloud(background_color=\"white\", max_words=100)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(data.subreddit)\n",
    "\n",
    "nsubs  = 6\n",
    "nwords = 10\n",
    "\n",
    "for i in np.random.randint(len(data.loc[:,'subreddit'].drop_duplicates())+1, size=nsubs):\n",
    "    wc.generate(data.body[y==i].str.cat(sep=' ')) # tokenized by r\"\\w[\\w']+\"\n",
    "    \n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title('Wordcloud from /r/{}'.format(le.inverse_transform(i)))\n",
    "    plt.show()\n",
    "    \n",
    "    words = []\n",
    "    freqs = []\n",
    "    for word in wc.words_:\n",
    "        if wc.words_[word]!=0:\n",
    "            words.append(word)\n",
    "            freqs.append(wc.words_[word])\n",
    "    x = range(nwords,0,-1)\n",
    "    plt.barh(x,freqs[:nwords])\n",
    "    plt.yticks(x, np.asarray(words[:nwords]))\n",
    "    plt.title('Word Frequency in /r/{}'.format(le.inverse_transform(i)))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Wordclouds from all subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "wc_all = WordCloud(background_color=\"white\", max_words=100)\n",
    "\n",
    "wc_all.generate(data.body.str.cat(sep=' ')) # tokenized by r\"\\w[\\w']+\"\n",
    "\n",
    "plt.imshow(wc_all, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title('Wordcloud from all subreddits')\n",
    "plt.show()\n",
    "\n",
    "words_all = []\n",
    "freqs_all = []\n",
    "for word in wc_all.words_:\n",
    "    if wc_all.words_[word]!=0:\n",
    "        words_all.append(word)\n",
    "        freqs_all.append(wc_all.words_[word])\n",
    "x = range(nwords,0,-1)\n",
    "plt.barh(x,freqs_all[:nwords])\n",
    "plt.yticks(x, np.asarray(words_all[:nwords]))\n",
    "plt.title('Word Frequency in all subreddits')\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordclouds from /r/gaming and /r/politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = wc_all.stopwords\n",
    "stops.update(words_all)\n",
    "subs  = ['gaming','politics']\n",
    "nwords = 10\n",
    "\n",
    "for sub in subs:\n",
    "    wc = WordCloud(background_color=\"white\", max_words=20,stopwords=stops)\n",
    "    wc.generate(data.body[data.subreddit==sub].str.cat(sep=' ')) # tokenized by r\"\\w[\\w']+\"\n",
    "    \n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title('Wordcloud from /r/{}'.format(sub))\n",
    "    plt.show()\n",
    "    \n",
    "    words = []\n",
    "    freqs = []\n",
    "    for word in wc.words_:\n",
    "        if wc.words_[word]!=0:\n",
    "            words.append(word)\n",
    "            freqs.append(wc.words_[word])\n",
    "    x = range(nwords,0,-1)\n",
    "    plt.barh(x,freqs[:nwords])\n",
    "    plt.yticks(x, np.asarray(words[:nwords]))\n",
    "    plt.title('Word frequencies in /r/{}'.format(sub))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize comments\n",
    "Once the comments are cleaned up, they may be vectorized. The sklearn CountVectorizer is used, but with a custom tokenizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom tokenizer (NLTK)\n",
    "The text is stemmed (so conjugations of words are counted together) using the Natural Language Tool Kit (NLTK) WordNet lemmatizer and a modified NLTK part-of-speech tagger. The NLTK stopwords are discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk import wordnet\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "        self.stop = set(stopwords.words('english'))\n",
    "    def __call__(self, doc):\n",
    "        return [t.lower() for t in \n",
    "                [self.wnl.lemmatize(t,self.get_wordnet_pos(t)) for t, pos in pos_tag(word_tokenize(doc))] \n",
    "                if re.match(\"^[a-zA-Z0-9_]*$\", t) and t not in self.stop]\n",
    "    def get_wordnet_pos(self, treebank_tag):\n",
    "        '''https://stackoverflow.com/questions/15586721/, with default noun'''\n",
    "        if treebank_tag.startswith('J'):\n",
    "            return wordnet.wordnet.ADJ\n",
    "        elif treebank_tag.startswith('V'):\n",
    "            return wordnet.wordnet.VERB\n",
    "        elif treebank_tag.startswith('N'):\n",
    "            return wordnet.wordnet.NOUN\n",
    "        elif treebank_tag.startswith('R'):\n",
    "            return wordnet.wordnet.ADV\n",
    "        else:\n",
    "            return wordnet.NOUN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create term count matrix\n",
    "This is the most time-consuming step, taking five to six hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "print(\"Extracting term counts...\")\n",
    "count_vectorizer = CountVectorizer(tokenizer=LemmaTokenizer(), \n",
    "                                stop_words='english',\n",
    "                                max_df=0.5, # Do not include words if they are in over half the comments\n",
    "                                min_df=2,   # Do not include words if they are in only one comment\n",
    "                                )\n",
    "t0 = time()\n",
    "cts = count_vectorizer.fit_transform(data['body'].astype('unicode'))\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "# Save results for quick iteration\n",
    "import pickle\n",
    "with open('data/feature_names.pkl', 'wb') as fp:\n",
    "    pickle.dump(count_vectorizer.get_feature_names(), fp)\n",
    "from scipy.sparse import save_npz\n",
    "save_npz('data/term_counts.npz', cts)\n",
    "\n",
    "\n",
    "# #  Alternative to above text block:\n",
    "# from scipy.sparse import load_npz\n",
    "# cts = load_npz('data/term_counts.npz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create frequency matrices\n",
    "The term frequency and inverse document frequency matrices are computed from the term count matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "print(\"Extracting term frequency features...\")\n",
    "\n",
    "# Create tf matrix\n",
    "print(\"tf...\")\n",
    "tf_transformer = TfidfTransformer(norm='l2', use_idf=False)\n",
    "t0 = time()\n",
    "tf = tf_transformer.fit_transform(cts)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "# Create tf/idf matrix\n",
    "print(\"tfidf...\")\n",
    "tfidf_transformer = TfidfTransformer(norm='l2', use_idf=True)\n",
    "t0 = time()\n",
    "tfidf = tfidf_transformer.fit_transform(cts)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "\n",
    "# Save results for quick iteration\n",
    "from scipy.sparse import save_npz\n",
    "save_npz('data/tf.npz', tf)\n",
    "save_npz('data/tfidf.npz', tfidf)\n",
    "\n",
    "\n",
    "#  Alternative to above text block:\n",
    "# from scipy.sparse import load_npz\n",
    "# tf = load_npz('data/tf.npz')\n",
    "# tfidf = load_npz('data/tfidf.npz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate saved files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import load_npz\n",
    "import pickle\n",
    "\n",
    "print(\"Importing data...\")\n",
    "t0 = time()\n",
    "data_val = pd.read_pickle('data/prepped.pkl')\n",
    "with open('data/feature_names.pkl', 'rb') as fp:\n",
    "    feature_names_val = pickle.load(fp)\n",
    "cts_val = load_npz('data/term_counts.npz')\n",
    "tf_val = load_npz('data/tf.npz')\n",
    "tfidf_val = load_npz('data/tfidf.npz')\n",
    "print(\"done in %0.3fs\" % (time()-t0))\n",
    "\n",
    "print()\n",
    "\n",
    "n_comments = data_val.shape[0]\n",
    "print(\"There are %0.f comments.\" % n_comments)\n",
    "if cts_val.shape[0] != n_comments: print(\"Count matrix has too few rows: %0.0f\" % cts_val.shape[0])\n",
    "if tf_val.shape[0] != n_comments: print(\"TF matrix has too few rows: %0.0f\" % tf_val.shape[0])\n",
    "if tfidf_val.shape[0] != n_comments: print(\"TF/IDF matrix has too few rows: %0.0f\" % tfidf_val.shape[0])\n",
    "\n",
    "print()\n",
    "\n",
    "n_words = len(feature_names_val)\n",
    "print(\"There are %0.f words counted.\" % n_words)\n",
    "if cts_val.shape[1] != n_words: print(\"Count matrix has too few columns: %0.0f\" % cts_val.shape[1])\n",
    "if tf_val.shape[1] != n_words: print(\"TF matrix has too few columns: %0.0f\" % tf_val.shape[1])\n",
    "if tfidf_val.shape[1] != n_words: print(\"TF/IDF matrix has too few columns: %0.0f\" % tfidf_val.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat above processing with agglomeration\n",
    "Combine all comments from each subreddit into a single string, then repeat the vectorization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(tokenizer=LemmaTokenizer(), \n",
    "                                stop_words='english',\n",
    "                                max_df=0.5, # Do not include words if they are in over half the comments\n",
    "                                min_df=2,   # Do not include words if they are in only one comment\n",
    "                                )\n",
    "tf_transformer = TfidfTransformer(norm='l2', use_idf=False)\n",
    "tfidf_transformer = TfidfTransformer(norm='l2', use_idf=True)\n",
    "\n",
    "print(\"Combining subreddit comments into a single string...\"\n",
    "t0 = time()\n",
    "data_comments = data\n",
    "data = pd.DataFrame(columns=['body','subreddit'])\n",
    "for idx, sub in enumerate(data_comments.loc[:,'subreddit'].drop_duplicates()):\n",
    "    data.loc[idx] = [data_comments.body[\n",
    "        data_comments['subreddit']==sub].astype('unicode').str.cat(sep=' '), sub]\n",
    "print(\"done in %.3fs.\" % (time()-t0))\n",
    "\n",
    "print(\"Extracting term counts...\")\n",
    "t0 = time()\n",
    "cts = count_vectorizer.fit_transform(data['body'].astype('unicode'))\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Extracting term frequency features...\")\n",
    "\n",
    "print(\"tf...\")\n",
    "t0 = time()\n",
    "tf = tf_transformer.fit_transform(cts)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"tfidf...\")\n",
    "t0 = time()\n",
    "tfidf = tfidf_transformer.fit_transform(cts)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "\n",
    "# Save results for quick iteration\n",
    "data.to_pickle('data/prepped_sub.pkl')\n",
    "with open('data/feature_names_sub.pkl', 'wb') as fp:\n",
    "    pickle.dump(count_vectorizer.get_feature_names(), fp)\n",
    "save_npz('data/term_counts_sub.npz', cts)\n",
    "save_npz('data/tf_sub.npz', tf)\n",
    "save_npz('data/tfidf_sub.npz', tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_pickle('data/prepped_sub.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
