@article{Mosteller1963,
abstract = {This study has four purposes: to provide a comparison of discrimination methods; to explore the problems presented by techniques based strongly on Bayes' theorem when they are used in a data analysis of large scale; to solve the authorship question of The Federalist papers; and to propose routine methods for solving other authorship problems. Word counts are the variables used for discrimination. Since the topic written about heavily influences the rate with which a word is used, care in selection of words is necessary. The filler words of the language such as an, of, and upon, and, more generally, articles, prepositions, and conjunctions provide fairly stable rates, whereas more meaningful words like war, exectutive and legislature do not. After an investigation of the distribution of these counts, the authors execute an analysis employing the usual discriminant function an an analysis based on Bayesian methods. The conclusions about the authorship problem are that Madison rather than Hamilton wrote all 12 of the disputed papers. The findings about methods are presented in the closing section on conclusisoins. This reports, summarizing and abbreviating a forthcoming monograph, gives some of the results but very little of their empirical and theoretical foundation. It treats two of the four main studies presented in the monograph, and none of the side studies.},
author = {Mosteller, Frederick and Wallace, David L.},
booktitle = {Journal of the American Statistical Association},
doi = {10.1080/01621459.1963.10500849},
file = {:C$\backslash$:/Users/sfzba/Downloads/mosteller.pdf:pdf},
issn = {1537274X},
number = {302},
pages = {275--309},
title = {{Inference in an Authorship Problem}},
volume = {58},
year = {1963}
}

@article{Blei2003,
abstract = {We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.},
archivePrefix = {arXiv},
arxivId = {1111.6189v1},
author = {Blei, David M and Edu, Blei@cs Berkeley and Ng, Andrew Y and Edu, Ang@cs Stanford and Jordan, Michael I and Edu, Jordan@cs Berkeley},
doi = {10.1162/jmlr.2003.3.4-5.993},
eprint = {1111.6189v1},
file = {:C$\backslash$:/Users/sfzba/Downloads/blei03a.pdf:pdf},
isbn = {9781577352815},
issn = {15324435},
journal = {Journal of Machine Learning Research},
pages = {993--1022},
pmid = {21362469},
title = {{Latent Dirichlet Allocation}},
volume = {3},
year = {2003}
}


@book{fourthparadigm,
  abstract = {Increasingly, scientific breakthroughs will be powered by advanced computing capabilities that help researchers manipulate and explore massive datasets.

The speed at which any given scientific discipline advances will depend on how well its researchers collaborate with one another, and with technologists, in areas of eScience such as databases, workflow management, visualization, and cloud computing technologies.

In The Fourth Paradigm: Data-Intensive Scientific Discovery, the collection of essays expands on the vision of pioneering computer scientist Jim Gray for a new, fourth paradigm of discovery based on data-intensive science and offers insights into how it can be fully realized.},
  added-at = {2010-02-16T09:54:37.000+0100},
  address = {Redmond, Washington},
  editor = {Hey, Tony and Tansley, Stewart and Tolle, Kristin},
  interhash = {296450016ca8a5f8ab16ae4d92d1fc15},
  intrahash = {8b203c0313656b6ced70c14c86a4c42a},
  keywords = {research scholarly_communication science},
  publisher = {Microsoft Research},
  timestamp = {2010-02-16T09:54:54.000+0100},
  title = {The Fourth Paradigm: Data-Intensive Scientific Discovery},
  url = {http://research.microsoft.com/en-us/collaboration/fourthparadigm/},
  year = 2009
}

@misc{redditblog:2015,
   author = "Upvoted: The Official Reddit Blog",
   title = "Reddit in 2015",
   year = "2017",
   howpublished = {\url{https://redditblog.com/2015/12/31/reddit-in-2015/}},
   note = "[Online; accessed 24-November-2017]"
 }
 
 @misc{annoy,
 	author = {Bernhardsson, Erik},
 	title = "Annoy",
 	howpublished = {\url{https://pypi.python.org/pypi/annoy}},
 	note = "[Online; accessed 24-November-2017]"
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@inproceedings{gensim,
      title = {{Software Framework for Topic Modelling with Large Corpora}},
      author = {Radim {\v R}eh{\r u}{\v r}ek and Petr Sojka},
      booktitle = {{Proceedings of the LREC 2010 Workshop on New
           Challenges for NLP Frameworks}},
      pages = {45--50},
      year = 2010,
      month = May,
      day = 22,
      publisher = {ELRA},
      address = {Valletta, Malta},
      note={\url{http://is.muni.cz/publication/884893/en}},
      language={English}
}

@misc{keras,
  title={Keras},
  author={Chollet, Fran\c{c}ois and others},
  year={2015},
  publisher={GitHub},
  howpublished={\url{https://github.com/fchollet/keras}},
}


